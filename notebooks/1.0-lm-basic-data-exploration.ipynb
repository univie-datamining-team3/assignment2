{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Exploratory Data Analysis\n",
    "\n",
    "In this notebook I will demonstrate how to download the data and how to visualise one trip. The import statements can be seen as a default for the jupyter notebook in the cookiecutter environment. If you only want to download all the data call:\n",
    "\n",
    "``python src\\data\\make_data.py``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Load the \"autoreload\" extension\n",
    "%load_ext autoreload\n",
    "\n",
    "# always reload modules marked with \"%aimport\"\n",
    "%autoreload 1\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Visualisation Libraries\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.style.use('ggplot')\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "#####\n",
    "#\n",
    "# Default way of appending the src directory in the cookiecutter file structure\n",
    "#\n",
    "#####\n",
    "\n",
    "# add the 'src' directory as one where we can import modules\n",
    "src_dir = os.path.join(os.getcwd(), os.pardir, 'src')\n",
    "sys.path.append(src_dir)\n",
    "\n",
    "# By loading the dotenv we can access Environment variables setted int the dm_mobility_task/.env file\n",
    "# e.g. I setted there my token like this: \"KEY_LUKAS\"=1234, similary there is one for KEY_RAPHAEL and KEY_MORITZ\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "# import my method from the source code\n",
    "%aimport data.data_utils\n",
    "from data.data_utils import list_recorded_data\n",
    "from data.data_utils import download_data_sets\n",
    "from data.data_utils import get_data_per_trip, get_data_per_token\n",
    "from data.data_utils import download_all\n",
    "from data.data_utils import VALID_NAMES\n",
    "from data.data_utils import get_trip_summaries\n",
    "%aimport visualization.visualize\n",
    "from visualization.visualize import plot_track\n",
    "%aimport data.preprocessing\n",
    "from data.preprocessing import downsample_time_series, convert_timestamps\n",
    "from data.preprocessing import downsample_time_series_per_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_name</th>\n",
       "      <th>last_modified</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>358568053229914_20171121-144912</td>\n",
       "      <td>2017-11-21 15:00</td>\n",
       "      <td>82K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>358568053229914_20171121-145403</td>\n",
       "      <td>2017-11-21 15:00</td>\n",
       "      <td>122K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>358568053229914_20171127-181845</td>\n",
       "      <td>2017-11-27 18:40</td>\n",
       "      <td>605K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>358568053229914_20171128-130428</td>\n",
       "      <td>2017-11-28 18:00</td>\n",
       "      <td>173K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358568053229914_20171128-163426</td>\n",
       "      <td>2017-11-28 18:00</td>\n",
       "      <td>638K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>358568053229914_20171128-174241</td>\n",
       "      <td>2017-11-28 18:00</td>\n",
       "      <td>707K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>358568053229914_20171130-110040</td>\n",
       "      <td>2017-11-30 11:20</td>\n",
       "      <td>647K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         full_name       last_modified  size\n",
       "0  358568053229914_20171121-144912  2017-11-21 15:00     82K\n",
       "1  358568053229914_20171121-145403  2017-11-21 15:00    122K\n",
       "2  358568053229914_20171127-181845  2017-11-27 18:40    605K\n",
       "3  358568053229914_20171128-130428  2017-11-28 18:00    173K\n",
       "4  358568053229914_20171128-163426  2017-11-28 18:00    638K\n",
       "5  358568053229914_20171128-174241  2017-11-28 18:00    707K\n",
       "6  358568053229914_20171130-110040  2017-11-30 11:20    647K"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the environment variable specified in .env\n",
    "# lists the recorded data by user\n",
    "token = os.environ.get(\"KEY_RAPHAEL\")\n",
    "recorded_trips = list_recorded_data(token)\n",
    "recorded_trips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to avoid too many request to the server we can use the **full_name** column to download the data and save it to data/raw, but download_data_sets(token) can also download the data per token, or all data from our team can be downloaded with download_all()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded  358568053229914_20171121-144912.csv.tar.gz\n",
      "Downloaded  358568053229914_20171121-145403.csv.tar.gz\n",
      "Downloaded  358568053229914_20171127-181845.csv.tar.gz\n",
      "Downloaded  358568053229914_20171128-130428.csv.tar.gz\n",
      "Downloaded  358568053229914_20171128-163426.csv.tar.gz\n",
      "Downloaded  358568053229914_20171128-174241.csv.tar.gz\n",
      "Downloaded  358568053229914_20171130-110040.csv.tar.gz\n",
      "Downloaded  355007075245007_20171108-110713.csv.tar.gz\n",
      "Downloaded  355007075245007_20171108-132646.csv.tar.gz\n",
      "Downloaded  355007075245007_20171121-140720.csv.tar.gz\n",
      "Downloaded  355007075245007_20171121-141338.csv.tar.gz\n",
      "Downloaded  868049020858898_20171109-131946.csv.tar.gz\n",
      "Downloaded  868049020858898_20171116-074009.csv.tar.gz\n",
      "Downloaded  868049020858898_20171123-072847.csv.tar.gz\n",
      "Downloaded  868049020858898_20171123-074632.csv.tar.gz\n",
      "Downloaded  868049020858898_20171128-164017.csv.tar.gz\n",
      "Downloaded  868049020858898_20171128-165210.csv.tar.gz\n",
      "Downloaded  868049020858898_20171130-074628.csv.tar.gz\n"
     ]
    }
   ],
   "source": [
    "# download_data_sets(token) works as well, \n",
    "# but than list_recorded_data is invoked again\n",
    "# we can also download all data for our team by \n",
    "download_all()\n",
    "tar_file_names = list(recorded_trips[\"full_name\"] + \".csv.tar.gz\")\n",
    "#download_data_sets(token, file_names=tar_file_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data has now been downloaded in dm_mobility_task/data/raw/token, we can check that by calling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have recorded: 18 trips\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['358568053229914/358568053229914_20171127-181845.csv.tar.gz',\n",
       " '358568053229914/358568053229914_20171128-163426.csv.tar.gz',\n",
       " '358568053229914/358568053229914_20171128-130428.csv.tar.gz',\n",
       " '358568053229914/358568053229914_20171121-144912.csv.tar.gz',\n",
       " '358568053229914/358568053229914_20171128-174241.csv.tar.gz',\n",
       " '358568053229914/358568053229914_20171130-110040.csv.tar.gz',\n",
       " '358568053229914/358568053229914_20171121-145403.csv.tar.gz',\n",
       " '355007075245007/355007075245007_20171108-132646.csv.tar.gz',\n",
       " '355007075245007/355007075245007_20171121-141338.csv.tar.gz',\n",
       " '355007075245007/355007075245007_20171108-110713.csv.tar.gz',\n",
       " '355007075245007/355007075245007_20171121-140720.csv.tar.gz',\n",
       " '868049020858898/868049020858898_20171123-074632.csv.tar.gz',\n",
       " '868049020858898/868049020858898_20171116-074009.csv.tar.gz',\n",
       " '868049020858898/868049020858898_20171109-131946.csv.tar.gz',\n",
       " '868049020858898/868049020858898_20171128-164017.csv.tar.gz',\n",
       " '868049020858898/868049020858898_20171128-165210.csv.tar.gz',\n",
       " '868049020858898/868049020858898_20171123-072847.csv.tar.gz',\n",
       " '868049020858898/868049020858898_20171130-074628.csv.tar.gz']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data.data_utils import get_file_names, get_data_dir\n",
    "# also possible for specific token\n",
    "# get_file_names(os.path.join(get_data_dir(),\"raw\"), token=token)\n",
    "recorded_file_names = get_file_names(os.path.join(get_data_dir(),\"raw\"))\n",
    "print(\"We have recorded: {} trips\".format(len(recorded_file_names)))\n",
    "recorded_file_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data has been downloaded, we can read it from file and start to explore it. I will here only explore data from my key, but with get_data_per_trip(dir_name=\"raw\") it is possible to load all **raw** data per trip in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data per trip by for all users by invoking: get_data_per_trip(dir_name=\"raw\")\n",
    "#dfs=get_data_per_trip(dir_name=\"raw\")\n",
    "dfs=get_data_per_token(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data can now be accessed in the following way. Enter one of the following valid names as key in the dictionary:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['annotation', 'cell', 'event', 'location', 'mac', 'marker', 'sensor']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VALID_NAMES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E.g. for the sensor data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor</th>\n",
       "      <th>time</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>magnetic</td>\n",
       "      <td>1511803126089</td>\n",
       "      <td>166.750</td>\n",
       "      <td>-72.000</td>\n",
       "      <td>-86.750</td>\n",
       "      <td>201.283691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>acceleration</td>\n",
       "      <td>1511803126089</td>\n",
       "      <td>0.852</td>\n",
       "      <td>6.828</td>\n",
       "      <td>7.240</td>\n",
       "      <td>9.988247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>magnetic</td>\n",
       "      <td>1511803126099</td>\n",
       "      <td>166.750</td>\n",
       "      <td>-72.000</td>\n",
       "      <td>-86.750</td>\n",
       "      <td>201.283691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>acceleration</td>\n",
       "      <td>1511803126099</td>\n",
       "      <td>0.718</td>\n",
       "      <td>6.828</td>\n",
       "      <td>7.221</td>\n",
       "      <td>9.963933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>magnetic</td>\n",
       "      <td>1511803126109</td>\n",
       "      <td>166.750</td>\n",
       "      <td>-72.000</td>\n",
       "      <td>-86.750</td>\n",
       "      <td>201.283691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>acceleration</td>\n",
       "      <td>1511803126109</td>\n",
       "      <td>0.651</td>\n",
       "      <td>6.885</td>\n",
       "      <td>7.221</td>\n",
       "      <td>9.998494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>magnetic</td>\n",
       "      <td>1511803126119</td>\n",
       "      <td>166.750</td>\n",
       "      <td>-72.000</td>\n",
       "      <td>-86.750</td>\n",
       "      <td>201.283691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>acceleration</td>\n",
       "      <td>1511803126119</td>\n",
       "      <td>0.584</td>\n",
       "      <td>6.828</td>\n",
       "      <td>7.489</td>\n",
       "      <td>10.151244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>magnetic</td>\n",
       "      <td>1511803126129</td>\n",
       "      <td>163.250</td>\n",
       "      <td>-58.250</td>\n",
       "      <td>-88.000</td>\n",
       "      <td>194.390396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>acceleration</td>\n",
       "      <td>1511803126129</td>\n",
       "      <td>0.507</td>\n",
       "      <td>6.809</td>\n",
       "      <td>7.412</td>\n",
       "      <td>10.077563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sensor           time        x       y       z       total\n",
       "0      magnetic  1511803126089  166.750 -72.000 -86.750  201.283691\n",
       "1  acceleration  1511803126089    0.852   6.828   7.240    9.988247\n",
       "2      magnetic  1511803126099  166.750 -72.000 -86.750  201.283691\n",
       "3  acceleration  1511803126099    0.718   6.828   7.221    9.963933\n",
       "4      magnetic  1511803126109  166.750 -72.000 -86.750  201.283691\n",
       "5  acceleration  1511803126109    0.651   6.885   7.221    9.998494\n",
       "6      magnetic  1511803126119  166.750 -72.000 -86.750  201.283691\n",
       "7  acceleration  1511803126119    0.584   6.828   7.489   10.151244\n",
       "8      magnetic  1511803126129  163.250 -58.250 -88.000  194.390396\n",
       "9  acceleration  1511803126129    0.507   6.809   7.412   10.077563"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trip_nr = 0\n",
    "dfs[trip_nr][\"sensor\"].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get summaries for each recorded trip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values does not match length of index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-063129f19f56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_trip_summaries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Development/datamining/assignment2/notebooks/../src/data/data_utils.py\u001b[0m in \u001b[0;36mget_trip_summaries\u001b[0;34m(all_trips, convert_time)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mend_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_trips_copy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrip_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"marker\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Start\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart_times\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Stop\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend_times\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"trip_length\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstart\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_times\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstart_times\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Development/datamining/py3env/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2518\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2519\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2521\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Development/datamining/py3env/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2584\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2585\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2586\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Development/datamining/py3env/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, key, value, broadcast)\u001b[0m\n\u001b[1;32m   2758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2759\u001b[0m             \u001b[0;31m# turn me into an ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2760\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sanitize_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2761\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2762\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Development/datamining/py3env/lib/python3.5/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_sanitize_index\u001b[0;34m(data, index, copy)\u001b[0m\n\u001b[1;32m   3078\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3079\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Length of values does not match length of '\u001b[0m \u001b[0;34m'index'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3082\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPeriodIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values does not match length of index"
     ]
    }
   ],
   "source": [
    "get_trip_summaries(dfs, convert_time=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we are visualizing the acceleration data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acceleration_df = dfs[trip_nr][\"sensor\"]\n",
    "acceleration_df = acceleration_df[acceleration_df[\"sensor\"]==\"acceleration\"]\n",
    "acceleration_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick visualisation of the acceleration of one of my trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "small = acceleration_df.drop([\"sensor\",\"total\"],axis=1).set_index(\"time\")\n",
    "figsize=(12, 4)\n",
    "small[\"x\"].plot(figsize=figsize);\n",
    "plt.ylabel(\"x\")\n",
    "plt.show();\n",
    "\n",
    "small[\"y\"].plot(figsize=figsize);\n",
    "plt.ylabel(\"y\")\n",
    "plt.show();\n",
    "\n",
    "small[\"z\"].plot(figsize=figsize);\n",
    "plt.ylabel(\"z\")\n",
    "plt.show();\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the gps data on a google map and save it as html to disk:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_df = dfs[trip_nr][\"location\"]\n",
    "file_name = \"gps_test.html\"\n",
    "plot_track(location_df[[\"longitude\", \"latitude\"]], file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The track can now be viewed at:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join(\"reports\",\"maps\",file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "**Apply resampling in new time interval for coarser granularity**\n",
    "\n",
    "The following csv files include time columns: cell, event, location, marker, sensor.\n",
    "\n",
    "Lets see an example for the acceleration data for one trip. First we have to convert the integer timestamps int the time column to datetime objects. This can be done via the convert_timestamps function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acceleration_df = dfs[trip_nr][\"sensor\"]\n",
    "acceleration_df = acceleration_df[acceleration_df[\"sensor\"]==\"acceleration\"]\n",
    "acceleration_df = convert_timestamps(acceleration_df)\n",
    "acceleration_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can downsample the acceleration data from milliseconds to a 1 second interval, where the new aggregated values are aggregated via the mean. \n",
    "\n",
    "**Note** that this drops the sensor column and the sensor column has to be reappended. This is not an issue here because we have only one sensor type. If you want to keep the categorical variable, see next point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acceleration_df_resampled = downsample_time_series(acceleration_df, time_interval=\"1S\")\n",
    "acceleration_df_resampled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another possibility were we can keep all the categorical values is by using the downsample_time_series_per_category function, here shown for full sensor table.\n",
    "\n",
    "**Note** that here we did not convert the time column for dfs[trip_nr] before, thats why this step is also done implicitly, otherwise the resampling does not work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[trip_nr][\"sensor\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sensors_resampled = downsample_time_series_per_category(dfs[trip_nr][\"sensor\"],\n",
    "                                                            categorical_colnames=[\"sensor\"])\n",
    "\n",
    "all_sensors_resampled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we now once again plot the acceleration for the resampled version we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "small = acceleration_df_resampled\n",
    "figsize=(12, 4)\n",
    "small[\"x\"].plot(figsize=figsize);\n",
    "plt.ylabel(\"x\")\n",
    "plt.show();\n",
    "\n",
    "small[\"y\"].plot(figsize=figsize);\n",
    "plt.ylabel(\"y\")\n",
    "plt.show();\n",
    "\n",
    "small[\"z\"].plot(figsize=figsize);\n",
    "plt.ylabel(\"z\")\n",
    "plt.show();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 @ /development/datamining",
   "language": "python",
   "name": "datamining"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
